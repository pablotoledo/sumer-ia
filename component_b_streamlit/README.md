# ğŸš€ Sistema Multi-Agente de Procesamiento de Transcripciones

**Sistema LLM-agnÃ³stico que transforma transcripciones STT en documentos educativos con Q&A automÃ¡tico**

> ğŸ“¦ **Usa [UV](https://docs.astral.sh/uv/)** - Gestor de paquetes Python moderno. Instalar: `curl -LsSf https://astral.sh/uv/install.sh | sh`

## ğŸ¯ Â¿QuÃ© hace?

Procesa transcripciones de audio (Speech-to-Text) y las convierte en documentos educativos estructurados con:
- âœ… PuntuaciÃ³n y formato profesional
- âœ… TÃ­tulos y secciones organizadas
- âœ… Preguntas y respuestas automÃ¡ticas
- âœ… Soporte para reuniones y contenido lineal

## ğŸš€ Inicio RÃ¡pido

### 1. Instalar dependencias
```bash
uv sync
```

### 2. Configurar proveedor LLM
Edita `fastagent.config.yaml` con tu API key:

```yaml
# Azure OpenAI (recomendado)
azure:
  api_key: "tu-api-key"
  base_url: "https://tu-recurso.cognitiveservices.azure.com/"
  azure_deployment: "gpt-4.1"
  api_version: "2025-01-01-preview"

# O usa Ollama local
generic:
  api_key: "ollama"
  base_url: "http://localhost:11434/v1"
```

### 3A. Usar desde lÃ­nea de comandos (CLI)
```bash
# Procesamiento bÃ¡sico
fastagent-cli -i transcription.txt -o output.md

# Con configuraciÃ³n avanzada
fastagent-cli -i input.txt -o output.md --preset conservative --segmentation intelligent
```

### 3B. Ejecutar la interfaz web
```bash
uv run streamlit run streamlit_app/streamlit_app.py
```

Abre http://localhost:8501 en tu navegador.

## ğŸ—ï¸ Arquitectura del Sistema

### **Pipeline con SegmentaciÃ³n Inteligente GPT-4.1**

```mermaid
graph TD
    A[ğŸ“ Contenido de Entrada] --> B{TamaÃ±o del Contenido}

    B -->|>3000 palabras| C[ğŸ§  GPT-4.1 Intelligent Segmenter<br/>AnÃ¡lisis semÃ¡ntico completo]
    B -->|<3000 palabras| D[ğŸ“ SegmentaciÃ³n ProgramÃ¡tica<br/>Cortes cada 2500 palabras]

    C --> E[ğŸ“Š Plan de SegmentaciÃ³n JSON<br/>â€¢ Puntos de corte Ã³ptimos<br/>â€¢ Metadata por segmento<br/>â€¢ Topics & keywords]
    D --> F[ğŸ“‹ Segmentos Simples<br/>Cortes programÃ¡ticos]

    E --> G[ğŸ” Content Format Detector<br/>DetecciÃ³n de formato]
    F --> G

    G --> H{Â¿Formato?}

    H -->|ReuniÃ³n| I[ğŸ‘¥ Meeting Processor]
    H -->|Lineal| J[ğŸ“š Simple Processor]

    I --> K[ğŸ”„ Loop: Procesar Segmentos<br/>CONTEXTO LIMPIO por segmento]
    J --> K

    K --> L[ğŸ“„ Documentos Procesados<br/>Con Q&A por segmento]
    L --> M[ğŸ”— Ensamblado Final]
    M --> N[ğŸ“¥ Documento Final Estructurado]

    style A fill:#e1f5fe
    style C fill:#c8e6c9
    style D fill:#ffccbc
    style E fill:#d1c4e9
    style G fill:#fff3e0
    style K fill:#fff9c4
    style N fill:#4caf50
```

**Ventajas de la SegmentaciÃ³n Inteligente:**
- âœ… GPT-4.1 analiza hasta 1M tokens de contexto (24k palabras = 3% del lÃ­mite)
- âœ… Cortes en transiciones naturales de tema, no arbitrarios
- âœ… Metadata enriquecida para mejor procesamiento
- âœ… Contexto limpio por segmento (sin memoria entre segmentos)
- âœ… ~10 segmentos Ã³ptimos vs 30 arbitrarios para 24k palabras

### **Arquitectura Multi-Agente Especializada**

```mermaid
graph LR
    subgraph "ğŸ”§ Componente ProgramÃ¡tico (Sin LLM)"
        A[ğŸ§  IntelligentSegmenter<br/>â€¢ SegmentaciÃ³n semÃ¡ntica<br/>â€¢ Sentence transformers<br/>â€¢ 100% preservaciÃ³n garantizada]
    end

    subgraph "ğŸ¤– Pipeline de Agentes Especializados"
        B[ğŸ”¤ Punctuator<br/>â€¢ Solo puntuaciÃ³n<br/>â€¢ Temp: 0.3<br/>â€¢ Preserva todas las palabras]
        C[âœï¸ Formatter<br/>â€¢ Oral â†’ escrito<br/>â€¢ Temp: 0.4<br/>â€¢ Elimina fillers]
        D[ğŸ“ Titler<br/>â€¢ Solo tÃ­tulos<br/>â€¢ Temp: 0.5<br/>â€¢ 3-8 palabras]
        E[â“ QA Generator<br/>â€¢ Solo Q&A<br/>â€¢ Temp: 0.6<br/>â€¢ 3-5 preguntas]
    end

    subgraph "ğŸ›¡ï¸ Sistema de Robustez"
        F[ğŸ”„ Rate Limit Handler<br/>â€¢ Auto-retry en errores 429<br/>â€¢ Backoff exponencial<br/>â€¢ Progreso visual]
        G[ğŸ“Š Multimodal Context<br/>â€¢ ExtracciÃ³n real PDFs<br/>â€¢ Soporte multi-formato<br/>â€¢ ValidaciÃ³n documentos]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style B fill:#ffebee
    style C fill:#e8f5e8
    style D fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#ff9800
    style G fill:#f3e5f5
```

## ğŸ–¥ï¸ Interfaz Web

### PÃ¡ginas disponibles:
- **ğŸ  Dashboard**: Estado del sistema y acceso rÃ¡pido
- **âš™ï¸ ConfiguraciÃ³n**: GestiÃ³n de proveedores LLM (Azure, Ollama, OpenAI, Anthropic)
- **ğŸ“ Procesamiento**: Upload y procesamiento de archivos con progreso visual
- **ğŸ¤– Agentes**: GestiÃ³n de prompts, testing y configuraciÃ³n avanzada

### Flujo de uso:
1. **Configurar** proveedor LLM en la pÃ¡gina de ConfiguraciÃ³n
2. **Subir** transcripciÃ³n en la pÃ¡gina de Procesamiento
3. **Procesar** con visualizaciÃ³n en tiempo real
4. **Descargar** resultados en TXT o MD

## ğŸ§  SegmentaciÃ³n Inteligente con GPT-4.1

### **MÃ©todo AutomÃ¡tico vs ProgramÃ¡tico**

El sistema ofrece dos mÃ©todos de segmentaciÃ³n seleccionables desde la UI:

#### ğŸ§  SegmentaciÃ³n Inteligente (Recomendado para >3000 palabras)
- **AnÃ¡lisis completo**: GPT-4.1 analiza todo el contenido (hasta 1M tokens)
- **Cortes semÃ¡nticos**: Identifica transiciones naturales de tema
- **Metadata enriquecida**: Genera tÃ­tulo, keywords y conceptos clave por segmento
- **Resultado**: Plan JSON con puntos de corte Ã³ptimos

**Ejemplo para 24,000 palabras:**
- âœ… ~10 segmentos coherentes (vs 30 arbitrarios)
- âœ… Cada segmento es una unidad lÃ³gica completa
- âœ… Costo: ~$0.10 adicional por anÃ¡lisis inicial

#### ğŸ“ SegmentaciÃ³n ProgramÃ¡tica (RÃ¡pido para <3000 palabras)
- DivisiÃ³n cada 2500 palabras buscando lÃ­mites de oraciones
- Sin costo adicional de anÃ¡lisis
- Recomendado para contenido corto donde la velocidad es prioritaria

### **Contexto Limpio por Segmento**

**Clave del diseÃ±o:** Cada segmento se procesa con `async with agent.run()`, creando una **nueva sesiÃ³n** sin memoria del segmento anterior.

```python
for segment in segments:
    async with agent.run() as agent_instance:  # ğŸ‘ˆ Nueva sesiÃ³n = contexto limpio
        result = await agent_instance.process(segment)
```

Esto garantiza:
- âœ… No hay "arrastre" de contexto entre segmentos
- âœ… Cada segmento se evalÃºa independientemente
- âœ… Procesamiento mÃ¡s consistente y predecible

## ğŸ¤– Agentes Especializados

El sistema usa mÃºltiples agentes especializados:

1. **Intelligent Segmenter** (GPT-4.1) - AnÃ¡lisis semÃ¡ntico y plan de segmentaciÃ³n
2. **Punctuator** (temp=0.3) - AÃ±ade puntuaciÃ³n y capitalizaciÃ³n
3. **Formatter** (temp=0.4) - Estructura el contenido en secciones
4. **Titler** (temp=0.5) - Genera tÃ­tulos descriptivos
5. **QA Generator** (temp=0.6) - Crea preguntas y respuestas educativas

## ğŸ“‚ Formatos Soportados

- **Archivos de texto** (.txt)
- **Documentos** (.md, .pdf, .docx)
- **Transcripciones STT** (cualquier formato de texto)
- **Reuniones diarizadas** (detecciÃ³n automÃ¡tica)

## âš™ï¸ ConfiguraciÃ³n

### Proveedores LLM soportados:
- **Azure OpenAI** (recomendado para espaÃ±ol)
- **Ollama** (local, gratuito)
- **OpenAI** (GPT-4, o1-mini)
- **Anthropic** (Claude)

### Rate Limiting inteligente:
El sistema incluye **prevenciÃ³n proactiva** de errores 429:
- **Delay entre segmentos**: Espera configurable entre requests (evita saturar API)
- **Reintentos automÃ¡ticos**: Backoff exponencial en caso de error 429
- **ConfiguraciÃ³n flexible**: Ajustable desde UI con presets (Conservador/Balanceado/Agresivo)

```yaml
rate_limiting:
  requests_per_minute: 3
  delay_between_requests: 30      # PrevenciÃ³n proactiva (delay entre segmentos)
  max_retries: 3                  # Reintentos en caso de 429
  retry_base_delay: 60            # Delay inicial (backoff exponencial)
  max_tokens_per_request: 50000
```

## ğŸ› ï¸ Scripts Disponibles

```bash
# CLI de procesamiento (nuevo)
fastagent-cli -i input.txt -o output.md

# Interfaz web principal
fastagent-ui

# Dashboard alternativo
fastagent-dashboard

# Script legacy de procesamiento
uv run python robust_main.py --input archivo.txt --output resultado.md
```

---

## ğŸ’» Uso del CLI (Command-Line Interface)

### **InstalaciÃ³n y ConfiguraciÃ³n**

```bash
# 1. Instalar dependencias
uv sync

# 2. Copiar plantilla de variables de entorno
cp .env.example .env

# 3. Editar .env con tus credenciales
nano .env

# 4. Verificar instalaciÃ³n
fastagent-cli --version
```

### **Ejemplos de Uso**

#### **BÃ¡sico**
```bash
# Procesamiento simple
fastagent-cli -i transcription.txt -o output.md
```

#### **Con Documentos Adicionales (Multimodal)**
```bash
# Incluir PDFs, imÃ¡genes u otros documentos para contexto
fastagent-cli -i input.txt -o output.md -d slides.pdf notes.txt diagram.png
```

#### **Usando Presets de ConfiguraciÃ³n**
```bash
# Para ambientes con rate limiting estricto (Azure S0)
fastagent-cli -i input.txt -o output.md --preset conservative

# Balance entre velocidad y calidad
fastagent-cli -i input.txt -o output.md --preset balanced

# MÃ¡xima calidad con segmentaciÃ³n AI
fastagent-cli -i input.txt -o output.md --preset intelligent

# MÃ¡xima velocidad
fastagent-cli -i input.txt -o output.md --preset fast
```

#### **ConfiguraciÃ³n Avanzada**
```bash
# SegmentaciÃ³n inteligente con GPT-4.1
fastagent-cli -i input.txt -o output.md --segmentation intelligent

# Agente especÃ­fico para reuniones
fastagent-cli -i meeting.txt -o output.md --agent meeting_processor

# Control manual de rate limiting
fastagent-cli -i input.txt -o output.md \
  --delay 45 \
  --max-retries 5 \
  --retry-delay 90

# Sin Q&A (mÃ¡s rÃ¡pido)
fastagent-cli -i input.txt -o output.md --no-qa

# Modo verbose para debugging
fastagent-cli -i input.txt -o output.md -v

# Simular sin hacer llamadas LLM
fastagent-cli -i input.txt -o output.md --dry-run
```

#### **Usando Variables de Entorno**
```bash
# Configurar variables de entorno
export FASTAGENT_MODEL=azure.gpt-4.1
export FASTAGENT_DELAY=45
export FASTAGENT_PROVIDER=azure

# Ejecutar sin argumentos adicionales
fastagent-cli -i input.txt -o output.md
```

### **Opciones Disponibles**

#### **Argumentos Requeridos**
```
-i, --input          Archivo de entrada (TXT, MD, PDF, DOCX)
-o, --output         Archivo de salida (MD, TXT)
```

#### **Input/Output**
```
-d, --documents      Documentos adicionales para contexto multimodal
--output-format      Formato de salida (md, txt) [default: md]
```

#### **Modelo y Proveedor**
```
--model              Modelo a usar (azure.gpt-4.1, generic.llama3.1, etc.)
--provider           Proveedor LLM (azure, ollama, openai, anthropic)
--config             Archivo de configuraciÃ³n [default: fastagent.config.yaml]
```

#### **Procesamiento**
```
--agent              Agente a usar (auto, simple_processor, meeting_processor)
--segmentation       MÃ©todo de segmentaciÃ³n (intelligent, programmatic, auto)
--enable-qa          Habilitar generaciÃ³n de Q&A [default: enabled]
--no-qa              Deshabilitar generaciÃ³n de Q&A
--qa-questions       NÃºmero de preguntas por segmento [default: 4]
```

#### **Rate Limiting**
```
--preset             Preset de configuraciÃ³n (fast, balanced, conservative, intelligent)
--delay              Delay entre requests en segundos
--max-retries        MÃ¡ximo de reintentos en error 429
--retry-delay        Delay base para reintentos (backoff exponencial)
```

#### **General**
```
-v, --verbose        Logging detallado
--no-progress        Desactivar barra de progreso
--dry-run            Simular procesamiento sin LLM calls
--version            Mostrar versiÃ³n
```

### **Presets Explicados**

| Preset | SegmentaciÃ³n | Q&A | Delay | Retries | Uso Recomendado |
|--------|-------------|-----|-------|---------|-----------------|
| **fast** | ProgramÃ¡tica | No | 10s | 2 | Procesamiento rÃ¡pido, sin Q&A |
| **balanced** | Auto | SÃ­ (3) | 20s | 3 | Balance velocidad/calidad (default) |
| **conservative** | ProgramÃ¡tica | SÃ­ (4) | 45s | 5 | Azure S0 tier, rate limiting estricto |
| **intelligent** | AI (GPT-4.1) | SÃ­ (5) | 30s | 3 | MÃ¡xima calidad, contenido >3000 palabras |

### **Variables de Entorno**

Crea un archivo `.env` basado en `.env.example`:

```bash
# General
FASTAGENT_PROVIDER=azure
FASTAGENT_MODEL=azure.gpt-4.1
FASTAGENT_OUTPUT_DIR=./output

# Rate Limiting
FASTAGENT_DELAY=30
FASTAGENT_MAX_RETRIES=3
FASTAGENT_RETRY_DELAY=60

# Azure OpenAI
AZURE_API_KEY=your-key
AZURE_BASE_URL=https://your-resource.cognitiveservices.azure.com/
AZURE_DEPLOYMENT=gpt-4.1
AZURE_API_VERSION=2025-01-01-preview

# Ollama
OLLAMA_BASE_URL=http://localhost:11434/v1

# OpenAI
OPENAI_API_KEY=your-key

# Anthropic
ANTHROPIC_API_KEY=your-key
```

### **Salida del CLI**

El CLI muestra:

1. **Resumen de configuraciÃ³n** antes de procesar
2. **Barra de progreso** durante procesamiento
3. **EstadÃ­sticas finales** al completar:
   - Tiempo de procesamiento
   - Segmentos procesados
   - MÃ©todo de segmentaciÃ³n usado
   - Tasa de retenciÃ³n de contenido
   - Reintentos por rate limiting

**Ejemplo de salida:**

```
============================================================
CONFIGURATION SUMMARY
============================================================
Input:              transcription.txt
Output:             output.md
Model:              azure.gpt-4.1
Agent:              auto
Segmentation:       intelligent
Q&A Generation:     Enabled
  Questions/segment: 4

Rate Limiting:
  Delay:            30s between requests
  Max retries:      3
  Retry delay:      60s base
============================================================

ğŸ“Š Estimated processing time: ~5 minutes
ğŸ“ Content size: 5,432 words

[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% - Â¡Procesamiento completado!

============================================================
PROCESSING COMPLETED SUCCESSFULLY
============================================================

â±ï¸  Processing Time: 312.5 seconds
ğŸ“ Output File: output.md

ğŸ“Š Statistics:
   Agent used:       simple_processor
   Segmentation:     intelligent_ai
   Total segments:   4
   Retry count:      0

ğŸ“ Content:
   Original words:   5,432
   Final words:      5,891
   Retention rate:   108.4%

============================================================
```

### **Troubleshooting CLI**

#### **Error: Command not found: fastagent-cli**
```bash
# Reinstalar
uv sync

# O ejecutar directamente
uv run python fastagent_cli.py -i input.txt -o output.md
```

#### **Error: Input file not found**
Verifica que la ruta sea correcta y que el archivo exista.

#### **Error: No LLM provider configured**
```bash
# Verificar configuraciÃ³n
cat fastagent.config.yaml

# O usar variables de entorno
export FASTAGENT_MODEL=azure.gpt-4.1
export AZURE_API_KEY=your-key
```

#### **Muchos reintentos por rate limiting**
```bash
# Aumentar delay
fastagent-cli -i input.txt -o output.md --delay 60

# O usar preset conservador
fastagent-cli -i input.txt -o output.md --preset conservative
```

---

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
uv run pytest tests/ -v

# Test especÃ­fico de Streamlit
uv run python test_streamlit_integration.py
```

## ğŸ“Š CaracterÃ­sticas TÃ©cnicas

- **LLM-agnÃ³stico**: Funciona con cualquier proveedor
- **SegmentaciÃ³n inteligente**: Divide contenido largo automÃ¡ticamente (GPT-4.1 o programÃ¡tico)
- **PreservaciÃ³n de contenido**: 85-95% del contenido original conservado
- **Auto-detecciÃ³n**: Distingue reuniones de contenido lineal
- **Multimodal**: Soporte para imÃ¡genes en contexto
- **Escalable**: Maneja desde 200 a 22,000+ palabras
- **Rate limiting inteligente**: PrevenciÃ³n proactiva de errores 429 con delays configurables

## ğŸ”§ SoluciÃ³n de Problemas

### Error "Azure OpenAI no estÃ¡ configurado"
- Verificar API key en `fastagent.config.yaml`
- Comprobar que la URL base sea correcta

### Errores 429 (Rate Limit)
El sistema ahora incluye **prevenciÃ³n automÃ¡tica**, pero si aÃºn asÃ­ ocurren:
1. **Aumentar `delay_between_requests`** en âš™ï¸ ConfiguraciÃ³n â†’ Rate Limiting
   - Para S0 Tier: usar preset ğŸŒ Conservador (45s delay)
2. **Ajustar `max_retries`** y `retry_base_delay`
   - MÃ¡s reintentos = mÃ¡s tolerancia a errores
3. **Revisar mÃ©tricas** despuÃ©s de procesar
   - Si "Reintentos por rate limit" > 3, aumentar delays
4. Ver `RATE_LIMIT_IMPROVEMENTS.md` para configuraciÃ³n detallada por tier

### Problemas de dependencias
```bash
uv sync --reinstall
```