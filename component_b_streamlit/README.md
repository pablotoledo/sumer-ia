# ğŸš€ Sistema Multi-Agente de Procesamiento de Transcripciones

**Sistema LLM-agnÃ³stico que transforma transcripciones STT en documentos educativos con Q&A automÃ¡tico**

> ğŸ“¦ **Usa [UV](https://docs.astral.sh/uv/)** - Gestor de paquetes Python moderno. Instalar: `curl -LsSf https://astral.sh/uv/install.sh | sh`

## ğŸ¯ Â¿QuÃ© hace?

Procesa transcripciones de audio (Speech-to-Text) y las convierte en documentos educativos estructurados con:
- âœ… PuntuaciÃ³n y formato profesional
- âœ… TÃ­tulos y secciones organizadas
- âœ… Preguntas y respuestas automÃ¡ticas
- âœ… Soporte para reuniones y contenido lineal

## ğŸš€ Inicio RÃ¡pido

### 1. Instalar dependencias
```bash
uv sync
```

### 2. Configurar proveedor LLM
Edita `fastagent.config.yaml` con tu API key:

```yaml
# Azure OpenAI (recomendado)
azure:
  api_key: "tu-api-key"
  base_url: "https://tu-recurso.cognitiveservices.azure.com/"
  azure_deployment: "gpt-4.1"
  api_version: "2025-01-01-preview"

# O usa Ollama local
generic:
  api_key: "ollama"
  base_url: "http://localhost:11434/v1"
```

### 3. Ejecutar la interfaz web
```bash
uv run streamlit run streamlit_app/streamlit_app.py
```

Abre http://localhost:8501 en tu navegador.

## ğŸ—ï¸ Arquitectura del Sistema

### **Pipeline con SegmentaciÃ³n Inteligente GPT-4.1**

```mermaid
graph TD
    A[ğŸ“ Contenido de Entrada] --> B{TamaÃ±o del Contenido}

    B -->|>3000 palabras| C[ğŸ§  GPT-4.1 Intelligent Segmenter<br/>AnÃ¡lisis semÃ¡ntico completo]
    B -->|<3000 palabras| D[ğŸ“ SegmentaciÃ³n ProgramÃ¡tica<br/>Cortes cada 2500 palabras]

    C --> E[ğŸ“Š Plan de SegmentaciÃ³n JSON<br/>â€¢ Puntos de corte Ã³ptimos<br/>â€¢ Metadata por segmento<br/>â€¢ Topics & keywords]
    D --> F[ğŸ“‹ Segmentos Simples<br/>Cortes programÃ¡ticos]

    E --> G[ğŸ” Content Format Detector<br/>DetecciÃ³n de formato]
    F --> G

    G --> H{Â¿Formato?}

    H -->|ReuniÃ³n| I[ğŸ‘¥ Meeting Processor]
    H -->|Lineal| J[ğŸ“š Simple Processor]

    I --> K[ğŸ”„ Loop: Procesar Segmentos<br/>CONTEXTO LIMPIO por segmento]
    J --> K

    K --> L[ğŸ“„ Documentos Procesados<br/>Con Q&A por segmento]
    L --> M[ğŸ”— Ensamblado Final]
    M --> N[ğŸ“¥ Documento Final Estructurado]

    style A fill:#e1f5fe
    style C fill:#c8e6c9
    style D fill:#ffccbc
    style E fill:#d1c4e9
    style G fill:#fff3e0
    style K fill:#fff9c4
    style N fill:#4caf50
```

**Ventajas de la SegmentaciÃ³n Inteligente:**
- âœ… GPT-4.1 analiza hasta 1M tokens de contexto (24k palabras = 3% del lÃ­mite)
- âœ… Cortes en transiciones naturales de tema, no arbitrarios
- âœ… Metadata enriquecida para mejor procesamiento
- âœ… Contexto limpio por segmento (sin memoria entre segmentos)
- âœ… ~10 segmentos Ã³ptimos vs 30 arbitrarios para 24k palabras

### **Arquitectura Multi-Agente Especializada**

```mermaid
graph LR
    subgraph "ğŸ”§ Componente ProgramÃ¡tico (Sin LLM)"
        A[ğŸ§  IntelligentSegmenter<br/>â€¢ SegmentaciÃ³n semÃ¡ntica<br/>â€¢ Sentence transformers<br/>â€¢ 100% preservaciÃ³n garantizada]
    end

    subgraph "ğŸ¤– Pipeline de Agentes Especializados"
        B[ğŸ”¤ Punctuator<br/>â€¢ Solo puntuaciÃ³n<br/>â€¢ Temp: 0.3<br/>â€¢ Preserva todas las palabras]
        C[âœï¸ Formatter<br/>â€¢ Oral â†’ escrito<br/>â€¢ Temp: 0.4<br/>â€¢ Elimina fillers]
        D[ğŸ“ Titler<br/>â€¢ Solo tÃ­tulos<br/>â€¢ Temp: 0.5<br/>â€¢ 3-8 palabras]
        E[â“ QA Generator<br/>â€¢ Solo Q&A<br/>â€¢ Temp: 0.6<br/>â€¢ 3-5 preguntas]
    end

    subgraph "ğŸ›¡ï¸ Sistema de Robustez"
        F[ğŸ”„ Rate Limit Handler<br/>â€¢ Auto-retry en errores 429<br/>â€¢ Backoff exponencial<br/>â€¢ Progreso visual]
        G[ğŸ“Š Multimodal Context<br/>â€¢ ExtracciÃ³n real PDFs<br/>â€¢ Soporte multi-formato<br/>â€¢ ValidaciÃ³n documentos]
    end

    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G

    style B fill:#ffebee
    style C fill:#e8f5e8
    style D fill:#e3f2fd
    style E fill:#fff3e0
    style F fill:#ff9800
    style G fill:#f3e5f5
```

## ğŸ–¥ï¸ Interfaz Web

### PÃ¡ginas disponibles:
- **ğŸ  Inicio**: Procesamiento rÃ¡pido de transcripciones
- **âš™ï¸ ConfiguraciÃ³n**: GestiÃ³n de proveedores LLM (BÃ¡sica/Avanzada/Experto)

### Flujo de uso:
1. **Configurar** proveedor LLM en la pÃ¡gina de ConfiguraciÃ³n
2. **Pegar/subir** transcripciÃ³n en la pÃ¡gina de Inicio
3. **Procesar** con visualizaciÃ³n en tiempo real
4. **Descargar** resultados en Markdown

## ğŸ§  SegmentaciÃ³n Inteligente con GPT-4.1

### **MÃ©todo AutomÃ¡tico vs ProgramÃ¡tico**

El sistema ofrece dos mÃ©todos de segmentaciÃ³n seleccionables desde la UI:

#### ğŸ§  SegmentaciÃ³n Inteligente (Recomendado para >3000 palabras)
- **AnÃ¡lisis completo**: GPT-4.1 analiza todo el contenido (hasta 1M tokens)
- **Cortes semÃ¡nticos**: Identifica transiciones naturales de tema
- **Metadata enriquecida**: Genera tÃ­tulo, keywords y conceptos clave por segmento
- **Resultado**: Plan JSON con puntos de corte Ã³ptimos

**Ejemplo para 24,000 palabras:**
- âœ… ~10 segmentos coherentes (vs 30 arbitrarios)
- âœ… Cada segmento es una unidad lÃ³gica completa
- âœ… Costo: ~$0.10 adicional por anÃ¡lisis inicial

#### ğŸ“ SegmentaciÃ³n ProgramÃ¡tica (RÃ¡pido para <3000 palabras)
- DivisiÃ³n cada 2500 palabras buscando lÃ­mites de oraciones
- Sin costo adicional de anÃ¡lisis
- Recomendado para contenido corto donde la velocidad es prioritaria

### **Contexto Limpio por Segmento**

**Clave del diseÃ±o:** Cada segmento se procesa con `async with agent.run()`, creando una **nueva sesiÃ³n** sin memoria del segmento anterior.

```python
for segment in segments:
    async with agent.run() as agent_instance:  # ğŸ‘ˆ Nueva sesiÃ³n = contexto limpio
        result = await agent_instance.process(segment)
```

Esto garantiza:
- âœ… No hay "arrastre" de contexto entre segmentos
- âœ… Cada segmento se evalÃºa independientemente
- âœ… Procesamiento mÃ¡s consistente y predecible

## ğŸ¤– Agentes Especializados

El sistema usa mÃºltiples agentes especializados:

1. **Intelligent Segmenter** (GPT-4.1) - AnÃ¡lisis semÃ¡ntico y plan de segmentaciÃ³n
2. **Punctuator** (temp=0.3) - AÃ±ade puntuaciÃ³n y capitalizaciÃ³n
3. **Formatter** (temp=0.4) - Estructura el contenido en secciones
4. **Titler** (temp=0.5) - Genera tÃ­tulos descriptivos
5. **QA Generator** (temp=0.6) - Crea preguntas y respuestas educativas

## ğŸ“‚ Formatos Soportados

- **Archivos de texto** (.txt)
- **Documentos** (.md, .pdf, .docx)
- **Transcripciones STT** (cualquier formato de texto)
- **Reuniones diarizadas** (detecciÃ³n automÃ¡tica)

## âš™ï¸ ConfiguraciÃ³n

### Proveedores LLM soportados:
- **Azure OpenAI** (recomendado para espaÃ±ol)
- **Ollama** (local, gratuito)
- **OpenAI** (GPT-4, o1-mini)
- **Anthropic** (Claude)

### Rate Limiting inteligente:
El sistema incluye **prevenciÃ³n proactiva** de errores 429:
- **Delay entre segmentos**: Espera configurable entre requests (evita saturar API)
- **Reintentos automÃ¡ticos**: Backoff exponencial en caso de error 429
- **ConfiguraciÃ³n flexible**: Ajustable desde UI con presets (Conservador/Balanceado/Agresivo)

```yaml
rate_limiting:
  requests_per_minute: 3
  delay_between_requests: 30      # PrevenciÃ³n proactiva (delay entre segmentos)
  max_retries: 3                  # Reintentos en caso de 429
  retry_base_delay: 60            # Delay inicial (backoff exponencial)
  max_tokens_per_request: 50000
```

## ğŸ› ï¸ Scripts Disponibles

```bash
# Interfaz web principal
fastagent-ui

# Procesamiento por lÃ­nea de comandos
uv run python scripts/cli.py --input archivo.txt --output resultado.md
```

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
uv run pytest tests/ -v

# Test de integraciÃ³n Streamlit
uv run python tests/integration/test_streamlit_integration.py
```

## ğŸ“Š CaracterÃ­sticas TÃ©cnicas

- **LLM-agnÃ³stico**: Funciona con cualquier proveedor
- **SegmentaciÃ³n inteligente**: Divide contenido largo automÃ¡ticamente (GPT-4.1 o programÃ¡tico)
- **PreservaciÃ³n de contenido**: 85-95% del contenido original conservado
- **Auto-detecciÃ³n**: Distingue reuniones de contenido lineal
- **Multimodal**: Soporte para imÃ¡genes en contexto
- **Escalable**: Maneja desde 200 a 22,000+ palabras
- **Rate limiting inteligente**: PrevenciÃ³n proactiva de errores 429 con delays configurables

## ğŸ”§ SoluciÃ³n de Problemas

### Error "Azure OpenAI no estÃ¡ configurado"
- Verificar API key en `fastagent.config.yaml`
- Comprobar que la URL base sea correcta

### Errores 429 (Rate Limit)
El sistema ahora incluye **prevenciÃ³n automÃ¡tica**, pero si aÃºn asÃ­ ocurren:
1. **Aumentar `delay_between_requests`** en âš™ï¸ ConfiguraciÃ³n â†’ Rate Limiting
   - Para S0 Tier: usar preset ğŸŒ Conservador (45s delay)
2. **Ajustar `max_retries`** y `retry_base_delay`
   - MÃ¡s reintentos = mÃ¡s tolerancia a errores
3. **Revisar mÃ©tricas** despuÃ©s de procesar
   - Si "Reintentos por rate limit" > 3, aumentar delays
4. Ver `docs/history/RATE_LIMIT_IMPROVEMENTS.md` para configuraciÃ³n detallada por tier

### Problemas de dependencias
```bash
uv sync --reinstall
```

## ğŸ“š DocumentaciÃ³n

- [GuÃ­a de Inicio RÃ¡pido](docs/QUICKSTART.md)
- [ConfiguraciÃ³n Detallada](docs/CONFIGURATION.md)
- [Funciones Avanzadas](docs/ADVANCED.md)