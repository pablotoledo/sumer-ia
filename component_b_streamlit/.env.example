# FastAgent CLI Environment Variables
# ====================================
# Copy this file to .env and fill in your values
# The CLI will automatically load these variables

# ===== GENERAL CONFIGURATION =====

# LLM Provider (azure, ollama, openai, anthropic)
FASTAGENT_PROVIDER=azure

# Model to use (e.g., azure.gpt-4.1, generic.llama3.1, gpt-4o, sonnet)
FASTAGENT_MODEL=azure.gpt-4.1

# Default output directory
FASTAGENT_OUTPUT_DIR=./output

# ===== RATE LIMITING =====

# Delay between requests in seconds (prevents rate limiting)
# Recommended: 30s for standard tier, 45s for S0 tier
FASTAGENT_DELAY=30

# Maximum retries on rate limit errors
FASTAGENT_MAX_RETRIES=3

# Base retry delay in seconds (exponential backoff)
FASTAGENT_RETRY_DELAY=60

# ===== AZURE OPENAI =====

# Azure OpenAI API Key
AZURE_API_KEY=your-azure-api-key-here

# Azure resource base URL
AZURE_BASE_URL=https://your-resource-name.cognitiveservices.azure.com/

# Azure deployment name
AZURE_DEPLOYMENT=gpt-4.1

# Azure API version
AZURE_API_VERSION=2025-01-01-preview

# ===== OLLAMA (Local/Remote) =====

# Ollama server base URL
# For local: http://localhost:11434/v1
# For remote: http://IP_ADDRESS:11434/v1
OLLAMA_BASE_URL=http://localhost:11434/v1

# ===== OPENAI =====

# OpenAI API Key
OPENAI_API_KEY=your-openai-api-key-here

# ===== ANTHROPIC =====

# Anthropic API Key
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ===== ADVANCED CONFIGURATION =====

# Enable verbose logging (true/false)
# FASTAGENT_VERBOSE=false

# Segmentation method (intelligent, programmatic, auto)
# FASTAGENT_SEGMENTATION=auto

# Enable Q&A generation (true/false)
# FASTAGENT_ENABLE_QA=true

# Number of Q&A questions per segment (1-10)
# FASTAGENT_QA_QUESTIONS=4
